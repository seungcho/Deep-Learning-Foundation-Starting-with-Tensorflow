{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lec 04: Multi-Variable linear regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-1.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위 그림과 같은 경우는 input(x)가 1개 즉, feature가 1인 경우의 데이터셋이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**하지만 머신러닝의 성능을 예측하는데 도움이 되는 x(feature)들이 많을수록 y를 예측하는 성능이 높아진다. 이에 따라 위 그림처럼 시험점수 예측에 도움이 되는 변수들 x1(quiz1),x2(quiz2),x3(midterm)를 추가한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위 데이터셋을 Hypothesis로 나타내면 H(x1(quiz1),x2(quiz2),x3(midterm)) = w1x1 + w2x2 + w3x3 + b로 나타낼 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**만약 feature의 개수가 N개라면 위 식처럼 나타낼 수 있다. 하지만 변수(feature)가 많아지면서 이것을 일일이 다써주는 것은 불편하다. 따라서 Matrix 연산을 통해 위 식을 간결하게 정리할 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**기존의 Hypothesis와는 다르게 X를 앞에 쓰는 이유는 앞에 오는 Matrix의 행과 뒤에 오는 Matrix의 열을 연산하기 때문에 XW의 형태를 취한다. 즉, Matrix 연산을 위함이다.**\n",
    "\n",
    "> **여기서 대문자 X는 (x1,x2,x3)의 Matrix를 뜻하고, W는 (w1,w2,w3)의 Matrix를 뜻한다.**\n",
    "\n",
    "**또한, Matrix 연산의 가장 큰 장점은 데이터의 개수와 상관없이 Matrix 연산이 가능하다는 점이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**위 그림을 보면 데이터의 레코드가 5개 이므로 X의 shape은 (5,3)이다. 그리고 x1,x2,x3의 대응하는 각각의 weight가 존재해야하므로 W의 shape은 (3,1)이 된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**따라서 H(X) = XW의 dot product를 진행하면 H(X)의 shape은 (5,1)이 된다. 이처럼 Matrix 연산을 통해 일일이 계산하지 않고 한번에 컴퓨터 연산이 가능해진다.**\n",
    "\n",
    "> **위 예제는 데이터의 레코드가 5개지만 데이터가 100,1000,N개 모두 Matrix 연산을 통해 한번에 계산 가능하다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**일반적으로 Matrix연산은 X의 행렬의 열과 W의 행의 차원이 같아야 연산이 가능해진다. 그리고 출력의 shape은 X 행렬의 행의 차원과 W 행렬의 열의 차원으로 출력이 이루어진다.**\n",
    "\n",
    "> **즉, 위의 예제에서 W의 shape의 행 차원은 X의 shape의 열 차원과 같아야 하므로 3이고, W의 열 차원은 출력 값의 열 차원과 같아야 하므로 2가 된다. 따라서 W의 최종 shape은 (3,2)가 된다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/lc4-11.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
